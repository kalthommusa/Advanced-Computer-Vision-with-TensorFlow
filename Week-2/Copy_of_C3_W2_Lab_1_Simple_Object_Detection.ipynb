{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmANPR2jhCR6"
      },
      "source": [
        "# Simple Object Detection in Tensorflow\n",
        "\n",
        "This lab will walk you through how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub). In the following sections, you will:\n",
        "\n",
        "* explore the Tensorflow Hub for object detection models\n",
        "* load the models in your workspace\n",
        "* preprocess an image for inference \n",
        "* run inference on the models and inspect the output\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install this package to use Colab's GPU for training\n",
        "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
      ],
      "metadata": {
        "id": "9Kom3HDMyxJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649492b5-cca7-4a42-b4a1-0606821fedbd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 420 MB of archives.\n",
            "After this operation, 1,622 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.4.1.50-1+cuda11.6 [420 MB]\n",
            "Fetched 420 MB in 7s (59.9 MB/s)\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "(Reading database ... 123993 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.4.1.50-1+cuda11.6_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.4.1.50-1+cuda11.6) over (8.1.1.33-1+cuda11.2) ...\n",
            "Setting up libcudnn8 (8.4.1.50-1+cuda11.6) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkMLuGDhCR6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEoRKdmByrb0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb8MBgTOhCR6"
      },
      "source": [
        "### Download the model from Tensorflow Hub\n",
        "\n",
        "Tensorflow Hub is a repository of trained machine learning models which you can reuse in your own projects. \n",
        "- You can see the domains covered [here](https://tfhub.dev/) and its subcategories. \n",
        "- For this lab, you will want to look at the [image object detection subcategory](https://tfhub.dev/s?module-type=image-object-detection). \n",
        "- You can select a model to see more information about it and copy the URL so you can download it to your workspace. \n",
        "- We selected a [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n",
        "- You can also modify this following cell to choose the other model that we selected, [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9pCzz4uy20U"
      },
      "source": [
        "# you can switch the commented lines here to pick the other model\n",
        "\n",
        "# inception resnet version 2\n",
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "\n",
        "# You can choose ssd mobilenet version 2 instead and compare the results\n",
        "#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3trj5FbhCR6"
      },
      "source": [
        "#### Load the model\n",
        "\n",
        "Next, you'll load the model specified by the `module_handle`.\n",
        "- This will take a few minutes to load the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WHkGDHfhCR6"
      },
      "source": [
        "model = hub.load(module_handle) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ey0FpHGhCR6"
      },
      "source": [
        "#### Choose the default signature\n",
        "\n",
        "Some models in the Tensorflow hub can be used for different tasks. So each model's documentation should show what *signature* to use when running the model. \n",
        "- If you want to see if a model has more than one signature then you can do something like `print(hub.load(module_handle).signatures.keys())`. In your case, the models you will be using only have the `default` signature so you don't have to worry about other types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1BU7AGthCR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9985f8dd-109a-43d2-c5db-bb2b3be29578"
      },
      "source": [
        "# take a look at the available signatures for this particular model\n",
        "model.signatures.keys()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x7F09B273A790>}))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfc9ax9hhCR6"
      },
      "source": [
        "Please choose the 'default' signature for your object detector.\n",
        "- For object detection models, its 'default' signature will accept a batch of image tensors and output a dictionary describing the objects detected, which is what you'll want here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzwR5zE_hCR7"
      },
      "source": [
        "detector = model.signatures['default']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#another diretct way\n",
        "#detector = hub.load(\"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\").signatures['default']"
      ],
      "metadata": {
        "id": "DgRIyeEt1xKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvb-3r3thCR7"
      },
      "source": [
        "### download_and_resize_image\n",
        "\n",
        "This function downloads an image specified by a given \"url\", pre-processes it, and then saves it to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucsxak_qhCR7"
      },
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256):\n",
        "    '''\n",
        "    Fetches an image online, resizes it and saves it locally.\n",
        "    \n",
        "    Args:\n",
        "        url (string) -- link to the image\n",
        "        new_width (int) -- size in pixels used for resizing the width of the image\n",
        "        new_height (int) -- size in pixels used for resizing the length of the image\n",
        "        \n",
        "    Returns:\n",
        "        (string) -- path to the saved image\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # create a temporary file ending with \".jpg\"\n",
        "    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "    \n",
        "    # opens the given URL\n",
        "    response = urlopen(url)\n",
        "    \n",
        "    # reads the image fetched from the URL\n",
        "    image_data = response.read()\n",
        "    \n",
        "    # puts the image data in memory buffer\n",
        "    image_data = BytesIO(image_data)\n",
        "    \n",
        "    # opens the image\n",
        "    pil_image = Image.open(image_data)\n",
        "    \n",
        "    # resizes the image. will crop if aspect ratio is different.\n",
        "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "    \n",
        "    # converts to the RGB colorspace\n",
        "    pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "    \n",
        "    # saves the image to the temporary file created earlier\n",
        "    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "    \n",
        "    print(\"Image downloaded to %s.\" % filename)\n",
        "    \n",
        "    return filename"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qodEJHhCR7"
      },
      "source": [
        "### Download and preprocess an image\n",
        "\n",
        "Now, using `download_and_resize_image` you can get a sample image online and save it locally. \n",
        "- We've provided a URL for you, but feel free to choose another image to run through the object detector.\n",
        "- You can use the original width and height of the image but feel free to modify it and see what results you get."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHTDalVrhCR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480c8e07-ab55-4983-97f7-5be72b3e644e"
      },
      "source": [
        "# You can choose a different URL that points to an image of your choice\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
        "\n",
        "# download the image and use the original height and width\n",
        "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image downloaded to /tmp/tmprqahilyx.jpg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVNXUKMIhCR7"
      },
      "source": [
        "### run_detector\n",
        "\n",
        "This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects and display its predicted class categories and detection boxes.\n",
        "- run_detector uses `load_image` to convert the image into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkkiQzKlhCR7"
      },
      "source": [
        "def load_img(path):\n",
        "    '''\n",
        "    Loads a JPEG image and converts it to a tensor.\n",
        "    \n",
        "    Args:\n",
        "        path (string) -- path to a locally saved JPEG image\n",
        "    \n",
        "    Returns:\n",
        "        (tensor) -- an image tensor\n",
        "    '''\n",
        "    \n",
        "    # read the file\n",
        "    img = tf.io.read_file(path)\n",
        "    \n",
        "    # convert to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    \n",
        "    return img\n",
        "\n",
        "\n",
        "def run_detector(detector, path):\n",
        "    '''\n",
        "    Runs inference on a local file using an object detection model.\n",
        "    \n",
        "    Args:\n",
        "        detector (model) -- an object detection model loaded from TF Hub\n",
        "        path (string) -- path to an image saved locally\n",
        "    '''\n",
        "    \n",
        "    # load an image tensor from a local file path\n",
        "    img = load_img(path)\n",
        "\n",
        "    # add a batch dimension in front of the tensor\n",
        "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "    \n",
        "    # run inference using the model\n",
        "    result = detector(converted_img)\n",
        "\n",
        "    # save the results in a dictionary\n",
        "    result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "    # print results\n",
        "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "\n",
        "    print(result[\"detection_scores\"])\n",
        "    print(result[\"detection_class_entities\"])\n",
        "    print(result[\"detection_boxes\"])\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSEeJSkxhCR7"
      },
      "source": [
        "### Run inference on the image\n",
        "\n",
        "You can run your detector by calling the `run_detector` function. This will print the number of objects found followed by three lists: \n",
        "\n",
        "* The detection scores of each object found (i.e. how confident the model is), \n",
        "* The classes of each object found, \n",
        "* The bounding boxes of each object\n",
        "\n",
        "You will see how to overlay this information on the original image in the next sections and in this week's assignment!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csanHvDIz4_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd26a811-5af6-400f-baff-9e2abc596c94"
      },
      "source": [
        "# runs the object detection model and prints information about the objects found\n",
        "run_detector(detector, downloaded_image_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 objects.\n",
            "[0.65321714 0.61050653 0.6015239  0.5925554  0.5917768  0.5815492\n",
            " 0.5505308  0.4957546  0.47424912 0.47322085 0.44066414 0.40511465\n",
            " 0.39803776 0.39406413 0.3714855  0.36156005 0.3615081  0.346891\n",
            " 0.33362454 0.3125292  0.28878042 0.2575832  0.25748903 0.25196037\n",
            " 0.24782032 0.23412381 0.20432086 0.2032459  0.17988263 0.1796481\n",
            " 0.17374507 0.1643153  0.16031064 0.15895212 0.15620287 0.15468831\n",
            " 0.1475445  0.13622625 0.12740074 0.12555623 0.12102654 0.11813053\n",
            " 0.1138732  0.11229075 0.11129197 0.09718709 0.09137286 0.08976004\n",
            " 0.08880263 0.0863357  0.08337477 0.08095109 0.07988653 0.07741472\n",
            " 0.07732126 0.07631037 0.0750786  0.07386053 0.0723329  0.07204084\n",
            " 0.07110164 0.06935596 0.06825599 0.06427874 0.06248556 0.06226425\n",
            " 0.06211179 0.0594006  0.05798777 0.05784452 0.05725601 0.05346696\n",
            " 0.05304351 0.05242857 0.04892573 0.04813062 0.04578466 0.0442417\n",
            " 0.0433757  0.0427782  0.04262597 0.041633   0.04081752 0.03975971\n",
            " 0.03945989 0.03944277 0.03864001 0.0376908  0.03759591 0.0356669\n",
            " 0.03359388 0.03333248 0.03275884 0.03231595 0.031343   0.02978718\n",
            " 0.02858353 0.02856123 0.02822316 0.02787891]\n",
            "[b'Person' b'Person' b'Person' b'Person' b'Footwear' b'Person' b'Building'\n",
            " b'Bicycle' b'Window' b'Building' b'Person' b'Wheel' b'Building'\n",
            " b'Building' b'Person' b'Wheel' b'Building' b'Window' b'Window'\n",
            " b'Building' b'Person' b'Van' b'Person' b'Bicycle wheel' b'Person'\n",
            " b'Window' b'Window' b'Bicycle' b'Building' b'Window' b'Window' b'Man'\n",
            " b'Person' b'Person' b'Woman' b'Clothing' b'Bicycle wheel' b'Window'\n",
            " b'Person' b'Window' b'Land vehicle' b'Land vehicle' b'Clothing'\n",
            " b'Bicycle' b'Window' b'House' b'Land vehicle' b'Land vehicle' b'House'\n",
            " b'Man' b'Window' b'Clothing' b'Footwear' b'Person' b'Window' b'Man'\n",
            " b'Man' b'House' b'Person' b'Building' b'Clothing' b'Window' b'Person'\n",
            " b'Jeans' b'Man' b'Furniture' b'Person' b'Person' b'Person'\n",
            " b'Land vehicle' b'Person' b'Window' b'House' b'Woman' b'Window' b'Man'\n",
            " b'Person' b'Man' b'Clothing' b'Bicycle' b'Man' b'Person' b'Window'\n",
            " b'Person' b'Car' b'Man' b'Car' b'Chair' b'House' b'Window' b'Clothing'\n",
            " b'Tire' b'Clothing' b'Window' b'Land vehicle' b'Window' b'Man' b'Window'\n",
            " b'Bus' b'Clothing']\n",
            "[[5.12787819e-01 5.29258847e-01 6.01622581e-01 5.52077651e-01]\n",
            " [5.19631088e-01 6.01512730e-01 6.46177113e-01 6.34626746e-01]\n",
            " [5.05507112e-01 5.00440836e-01 6.01288378e-01 5.23084342e-01]\n",
            " [4.86331582e-01 4.12729561e-01 6.78829789e-01 4.59919751e-01]\n",
            " [8.15191388e-01 9.56122220e-01 8.42702985e-01 9.87146080e-01]\n",
            " [4.95409906e-01 9.23548341e-01 8.35687816e-01 9.99051571e-01]\n",
            " [1.14791868e-02 1.22224605e-02 7.38669872e-01 4.24632818e-01]\n",
            " [5.77677429e-01 3.66453379e-01 7.12771595e-01 4.83375698e-01]\n",
            " [0.00000000e+00 1.19262375e-01 2.23896086e-01 1.83930486e-01]\n",
            " [7.74121359e-02 4.12998170e-01 5.79539895e-01 5.60446203e-01]\n",
            " [5.13818145e-01 7.48031378e-01 5.91993213e-01 7.66611278e-01]\n",
            " [6.32137895e-01 3.59925479e-01 7.03870296e-01 4.11826164e-01]\n",
            " [0.00000000e+00 7.97051966e-01 6.73368573e-01 1.00000000e+00]\n",
            " [1.60233825e-02 6.84869528e-01 5.58761537e-01 8.11168015e-01]\n",
            " [5.00276983e-01 3.76966298e-01 6.33272946e-01 4.14501339e-01]\n",
            " [6.40540302e-01 4.45089400e-01 7.02983618e-01 4.83437657e-01]\n",
            " [0.00000000e+00 2.19054237e-01 6.60401046e-01 4.33263451e-01]\n",
            " [1.93079631e-03 0.00000000e+00 1.39376864e-01 2.62956936e-02]\n",
            " [2.57197069e-03 9.66668665e-01 1.53728679e-01 1.00000000e+00]\n",
            " [5.57174673e-04 1.52054860e-03 7.65210688e-01 2.69977123e-01]\n",
            " [5.04524827e-01 3.61187756e-01 6.34731770e-01 3.85342211e-01]\n",
            " [4.83405828e-01 6.19650841e-01 5.62705755e-01 6.61556125e-01]\n",
            " [4.98067319e-01 3.64576191e-01 6.61239445e-01 4.04972345e-01]\n",
            " [6.31278813e-01 3.60364169e-01 7.04153776e-01 4.11501348e-01]\n",
            " [5.21813869e-01 5.77647567e-01 5.87599933e-01 6.00718856e-01]\n",
            " [2.19569609e-01 3.48744750e-01 3.38372618e-01 3.77075404e-01]\n",
            " [1.24863081e-01 2.50912935e-01 2.79940903e-01 2.81580776e-01]\n",
            " [5.77186048e-01 3.62296700e-01 7.07020819e-01 4.41810787e-01]\n",
            " [2.57474422e-01 5.67561567e-01 5.31102896e-01 6.87727273e-01]\n",
            " [4.20639366e-02 8.74773145e-01 2.52773494e-01 9.13028836e-01]\n",
            " [1.56351015e-01 4.43401128e-01 2.22213224e-01 4.75786120e-01]\n",
            " [5.01968026e-01 9.21486855e-01 8.36406708e-01 1.00000000e+00]\n",
            " [5.23622572e-01 5.70259511e-01 5.84519565e-01 5.91583431e-01]\n",
            " [5.13246477e-01 6.79276526e-01 5.50994456e-01 6.92579985e-01]\n",
            " [5.19120216e-01 5.99985421e-01 6.46378458e-01 6.34036481e-01]\n",
            " [5.24297774e-01 9.24962044e-01 8.10777009e-01 9.97999549e-01]\n",
            " [6.38187289e-01 4.42918181e-01 7.01653838e-01 4.84097779e-01]\n",
            " [3.42190675e-02 3.55574727e-01 1.62255064e-01 3.74921173e-01]\n",
            " [4.88476783e-01 4.53496963e-01 6.21795475e-01 4.79725718e-01]\n",
            " [9.28783440e-04 3.07699054e-01 1.06533416e-01 3.32059711e-01]\n",
            " [4.83008981e-01 6.19908273e-01 5.64775169e-01 6.60696924e-01]\n",
            " [5.82192838e-01 3.64929765e-01 7.13880658e-01 4.84707862e-01]\n",
            " [5.23547709e-01 7.49199331e-01 5.85378110e-01 7.65317559e-01]\n",
            " [6.09156847e-01 4.26705897e-01 7.05165267e-01 4.87089008e-01]\n",
            " [3.51368606e-01 9.74856079e-01 5.53130627e-01 9.98878717e-01]\n",
            " [0.00000000e+00 8.11223269e-01 6.86410785e-01 9.97151375e-01]\n",
            " [5.76297581e-01 3.57461840e-01 7.04812288e-01 4.40279603e-01]\n",
            " [5.64892411e-01 3.63023102e-01 7.08650231e-01 4.16036338e-01]\n",
            " [1.09375259e-02 2.33156346e-02 7.26523042e-01 4.21747655e-01]\n",
            " [4.84686643e-01 4.10686046e-01 6.94686472e-01 4.63092834e-01]\n",
            " [8.09777379e-02 3.84715289e-01 2.07808718e-01 4.11746383e-01]\n",
            " [5.38284421e-01 6.03573740e-01 6.34776115e-01 6.34408653e-01]\n",
            " [6.29844606e-01 6.14971459e-01 6.44933462e-01 6.25384331e-01]\n",
            " [5.02758026e-01 3.82395953e-01 5.96146226e-01 4.12722319e-01]\n",
            " [0.00000000e+00 1.24522941e-02 1.40193507e-01 2.47382168e-02]\n",
            " [5.14441371e-01 7.47791529e-01 5.91985822e-01 7.66827404e-01]\n",
            " [5.06182134e-01 5.00406921e-01 6.00681305e-01 5.23312032e-01]\n",
            " [0.00000000e+00 2.11283550e-01 6.50794208e-01 4.34300780e-01]\n",
            " [4.89451498e-01 4.54391301e-01 5.72340131e-01 4.76470768e-01]\n",
            " [0.00000000e+00 7.06215739e-01 6.16998494e-01 8.66189599e-01]\n",
            " [5.09172916e-01 4.16281193e-01 6.69304490e-01 4.59598720e-01]\n",
            " [4.65171831e-03 8.03094208e-01 1.59853578e-01 8.40397060e-01]\n",
            " [5.26151001e-01 5.68352938e-01 5.79440355e-01 5.82810223e-01]\n",
            " [6.71924829e-01 9.40277696e-01 8.21276009e-01 9.89250779e-01]\n",
            " [5.02770245e-01 3.73883098e-01 6.46991551e-01 4.12972301e-01]\n",
            " [5.74243903e-01 2.67400861e-01 6.57769084e-01 3.20318550e-01]\n",
            " [4.86056775e-01 4.44508791e-01 6.24788880e-01 4.73503351e-01]\n",
            " [5.17248988e-01 7.56969213e-01 5.88517189e-01 7.71465480e-01]\n",
            " [5.23374975e-01 5.57850122e-01 5.79139531e-01 5.73541582e-01]\n",
            " [6.12461030e-01 4.27332461e-01 7.06080198e-01 4.88251865e-01]\n",
            " [5.24124086e-01 5.61553180e-01 5.78385353e-01 5.80475152e-01]\n",
            " [0.00000000e+00 2.44231775e-01 6.07754737e-02 2.93613434e-01]\n",
            " [1.48920696e-02 2.14735954e-03 7.45442033e-01 2.59790659e-01]\n",
            " [4.93236095e-01 9.23950195e-01 8.37110698e-01 9.97755051e-01]\n",
            " [8.37684050e-03 2.42165700e-01 4.97285202e-02 2.83162564e-01]\n",
            " [5.05334914e-01 3.60175282e-01 6.43561006e-01 3.91461790e-01]\n",
            " [5.13099134e-01 5.23794115e-01 6.00504339e-01 5.42968035e-01]\n",
            " [5.20421386e-01 6.00978673e-01 6.46124065e-01 6.34366393e-01]\n",
            " [5.18224835e-01 5.03395557e-01 5.97548664e-01 5.22683859e-01]\n",
            " [5.94199181e-01 3.61327976e-01 7.05465853e-01 4.15853351e-01]\n",
            " [5.13256431e-01 6.79317057e-01 5.50533950e-01 6.92482233e-01]\n",
            " [5.22302687e-01 5.36195457e-01 5.97564995e-01 5.53163230e-01]\n",
            " [4.29876357e-01 8.28702271e-01 5.89928269e-01 8.64323139e-01]\n",
            " [5.04884660e-01 3.89426976e-01 6.15080774e-01 4.19936091e-01]\n",
            " [5.26588559e-01 6.27176881e-01 5.63299775e-01 6.53728902e-01]\n",
            " [5.01304924e-01 3.64189029e-01 6.59964740e-01 4.03793275e-01]\n",
            " [5.15171230e-01 6.24104798e-01 5.63795388e-01 6.58002079e-01]\n",
            " [5.73137939e-01 2.66902626e-01 6.66162014e-01 3.18640202e-01]\n",
            " [8.34236145e-02 4.07414347e-01 5.84092379e-01 5.58522880e-01]\n",
            " [2.88196921e-01 4.77990950e-04 4.14364636e-01 3.65995914e-02]\n",
            " [4.97272849e-01 4.55296665e-01 5.83817124e-01 4.77936029e-01]\n",
            " [6.27168000e-01 3.61024052e-01 7.05996811e-01 4.09780174e-01]\n",
            " [5.15861034e-01 3.80056977e-01 5.96893847e-01 4.11758274e-01]\n",
            " [1.18098166e-02 3.08121800e-01 9.72859487e-02 3.25038970e-01]\n",
            " [5.12501776e-01 6.23653412e-01 5.62422156e-01 6.57641828e-01]\n",
            " [4.01003093e-01 8.85088921e-01 5.81281543e-01 9.39214408e-01]\n",
            " [5.13853252e-01 5.29484570e-01 6.02009714e-01 5.52362800e-01]\n",
            " [0.00000000e+00 1.00606121e-02 1.36156842e-01 3.16007249e-02]\n",
            " [4.80426341e-01 6.20422781e-01 5.65284550e-01 6.60150409e-01]\n",
            " [5.19355476e-01 3.61840427e-01 6.24995410e-01 3.84919703e-01]]\n"
          ]
        }
      ]
    }
  ]
}